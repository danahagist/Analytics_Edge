{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Parole Violators\n",
    "## Compiled By: Dana Hagist\n",
    "### Solution Source, Analytics Edge\n",
    "\n",
    "This solution set was pulled from the project \"Predicting Parole Violators\" on the course Analytics Edge at:\n",
    "https://courses.edx.org/courses/course-v1:MITx+15.071x_3+1T2016/courseware/\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In many criminal justice systems around the world, inmates deemed not to be a threat to society are released from prison under the parole system prior to completing their sentence. They are still considered to be serving their sentence while on parole, and they can be returned to prison if they violate the terms of their parole.\n",
    "\n",
    "Parole boards are charged with identifying which inmates are good candidates for release on parole. They seek to release inmates who will not commit additional crimes after release. In this problem, we will build and validate a model that predicts if an inmate will violate the terms of his or her parole. Such a model could be useful to a parole board when deciding to approve or deny an application for parole.\n",
    "\n",
    "For this prediction task, we will use data from the United States 2004 National Corrections Reporting Program, a nationwide census of parole releases that occurred during 2004. We limited our focus to parolees who served no more than 6 months in prison and whose maximum sentence for all charges did not exceed 18 months. The dataset contains all such parolees who either successfully completed their term of parole during 2004 or those who violated the terms of their parole during that year. The dataset contains the following variables:\n",
    "\n",
    "- male: 1 if the parolee is male, 0 if female\n",
    "- race: 1 if the parolee is white, 2 otherwise\n",
    "- age: the parolee's age (in years) when he or she was released from prison\n",
    "- state: a code for the parolee's state. 2 is Kentucky, 3 is Louisiana, 4 is Virginia, and 1 is any other state. The three states were selected due to having a high representation in the dataset.\n",
    "- time.served: the number of months the parolee served in prison (limited by the inclusion criteria to not exceed 6 months).\n",
    "- max.sentence: the maximum sentence length for all charges, in months (limited by the inclusion criteria to not exceed 18 months).\n",
    "- multiple.offenses: 1 if the parolee was incarcerated for multiple offenses, 0 otherwise.\n",
    "- crime: a code for the parolee's main crime leading to incarceration. 2 is larceny, 3 is drug-related crime, 4 is driving-related crime, and 1 is any other crime.\n",
    "- violator: 1 if the parolee violated the parole, and 0 if the parolee completed the parole without violation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.1 - Loading the Dataset\n",
    "\n",
    "Load the dataset parole.csv into a data frame called parole, and investigate it using the str() and summary() functions.\n",
    "\n",
    "How many parolees are contained in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "675"
      ],
      "text/latex": [
       "675"
      ],
      "text/markdown": [
       "675"
      ],
      "text/plain": [
       "[1] 675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solution: \n",
    "setwd #Insert working directory between ticks('')\n",
    "parole = read.csv('parole.csv')\n",
    "nrow(parole)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.2 - Loading the Dataset\n",
    "\n",
    "How many of the parolees in the dataset violated the terms of their parole?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "597  78 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solution: \n",
    "table(parole$violator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the table above, 78 of the parolees violated the terms of their parole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.1 - Preparing the Dataset\n",
    "\n",
    "You should be familiar with unordered factors (if not, review the Week 2 homework problem \"Reading Test Scores\"). Which variables in this dataset are unordered factors with at least three levels? Select all that apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t675 obs. of  9 variables:\n",
      " $ male             : int  1 0 1 1 1 1 1 0 0 1 ...\n",
      " $ race             : int  1 1 2 1 2 2 1 1 1 2 ...\n",
      " $ age              : num  33.2 39.7 29.5 22.4 21.6 46.7 31 24.6 32.6 29.1 ...\n",
      " $ state            : int  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ time.served      : num  5.5 5.4 5.6 5.7 5.4 6 6 4.8 4.5 4.7 ...\n",
      " $ max.sentence     : int  18 12 12 18 12 18 18 12 13 12 ...\n",
      " $ multiple.offenses: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ crime            : int  4 3 3 1 1 4 3 1 3 2 ...\n",
      " $ violator         : int  0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "# Solution: \n",
    "str(parole)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the structure of the dataset above, male, race, state, and crime would be considered unordered factors.\n",
    "\n",
    "However, only state and crime have at least 3 levels in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Problem 2.2 - Preparing the Dataset\n",
    "\n",
    "In the last subproblem, we identified variables that are unordered factors with at least 3 levels, so we need to convert them to factors for our prediction problem (we introduced this idea in the \"Reading Test Scores\" problem last week). Using the as.factor() function, convert these variables to factors. Keep in mind that we are not changing the values, just the way R understands them (the values are still numbers).\n",
    "\n",
    "How does the output of summary() change for a factor variable as compared to a numerical variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      male             race            age        state    time.served   \n",
       " Min.   :0.0000   Min.   :1.000   Min.   :18.40   1:143   Min.   :0.000  \n",
       " 1st Qu.:1.0000   1st Qu.:1.000   1st Qu.:25.35   2:120   1st Qu.:3.250  \n",
       " Median :1.0000   Median :1.000   Median :33.70   3: 82   Median :4.400  \n",
       " Mean   :0.8074   Mean   :1.424   Mean   :34.51   4:330   Mean   :4.198  \n",
       " 3rd Qu.:1.0000   3rd Qu.:2.000   3rd Qu.:42.55           3rd Qu.:5.200  \n",
       " Max.   :1.0000   Max.   :2.000   Max.   :67.00           Max.   :6.000  \n",
       "  max.sentence   multiple.offenses crime      violator     \n",
       " Min.   : 1.00   Min.   :0.0000    1:315   Min.   :0.0000  \n",
       " 1st Qu.:12.00   1st Qu.:0.0000    2:106   1st Qu.:0.0000  \n",
       " Median :12.00   Median :1.0000    3:153   Median :0.0000  \n",
       " Mean   :13.06   Mean   :0.5363    4:101   Mean   :0.1156  \n",
       " 3rd Qu.:15.00   3rd Qu.:1.0000            3rd Qu.:0.0000  \n",
       " Max.   :18.00   Max.   :1.0000            Max.   :1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Solution: \n",
    "parole$state = as.factor(parole$state)\n",
    "\n",
    "parole$crime = as.factor(parole$crime)\n",
    "\n",
    "summary(parole)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of summary(parole\\$state) or summary(parole$crime) now shows a breakdown of the number of parolees with each level of the factor, which is most similar to the output of the table() function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3.1 - Splitting into a Training and Testing Set\n",
    "\n",
    "To ensure consistent training/testing set splits, run the following 5 lines of code (do not include the line numbers at the beginning):\n",
    "\n",
    "1) set.seed(144)\n",
    "\n",
    "2) library(caTools)\n",
    "\n",
    "3) split = sample.split(parole$violator, SplitRatio = 0.7)\n",
    "\n",
    "4) train = subset(parole, split == TRUE)\n",
    "\n",
    "5) test = subset(parole, split == FALSE)\n",
    "\n",
    "Roughly what proportion of parolees have been allocated to the training and testing sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution: \n",
    "set.seed(144)\n",
    "library(caTools)\n",
    "split = sample.split(parole$violator, SplitRatio = 0.7)\n",
    "train = subset(parole, split == TRUE)\n",
    "test = subset(parole, split == FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: \n",
    "\n",
    "SplitRatio=0.7 causes split to take the value TRUE roughly 70% of the time, so train should contain roughly 70% of the values in the dataset. You can verify this by running nrow(train) and nrow(test). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "473"
      ],
      "text/latex": [
       "473"
      ],
      "text/markdown": [
       "473"
      ],
      "text/plain": [
       "[1] 473"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "202"
      ],
      "text/latex": [
       "202"
      ],
      "text/markdown": [
       "202"
      ],
      "text/plain": [
       "[1] 202"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.700740740740741"
      ],
      "text/latex": [
       "0.700740740740741"
      ],
      "text/markdown": [
       "0.700740740740741"
      ],
      "text/plain": [
       "[1] 0.7007407"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(train)\n",
    "nrow(test)\n",
    "nrow(train)/(nrow(test)+nrow(train))\n",
    "# Can see in the results below the 70% allocated to the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3.2 - Splitting into a Training and Testing Set (answers inline)\n",
    "\n",
    "Now, suppose you re-ran lines [1]-[5] of Problem 3.1. What would you expect?\n",
    "\n",
    "- You would expect the same training/testing set split as the first execution.\n",
    "\n",
    "If you instead ONLY re-ran lines [3]-[5], what would you expect?\n",
    "\n",
    "- You would expect a different training/testing set split from the first execution.\n",
    "\n",
    "If you instead called set.seed() with a different number and then re-ran lines [3]-[5] of Problem 3.1, what would you expect?\n",
    "\n",
    "- You would expect a different training/testing set split from the first execution.\n",
    "\n",
    "\n",
    "Explanation\n",
    "\n",
    "If you set a random seed, split, set the seed again to the same value, and then split again, you will get the same split. However, if you set the seed and then split twice, you will get different splits. If you set the seed to different values, you will get different splits.\n",
    "\n",
    "You can also verify this by running the specified code in R. If you have training sets train1 and train2, the function sum(train1 != train2) will count the number of values in those two data frames that are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4.1 - Building a Logistic Regression Model\n",
    "\n",
    "If you tested other training/testing set splits in the previous section, please re-run the original 5 lines of code to obtain the original split.\n",
    "\n",
    "Using glm (and remembering the parameter family=\"binomial\"), train a logistic regression model on the training set. Your dependent variable is \"violator\", and you should use all of the other variables as independent variables.\n",
    "\n",
    "What variables are significant in this model? Significant variables should have a least one star, or should have a probability less than 0.05 (the column Pr(>|z|) in the summary output). Select all that apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = violator ~ ., family = \"binomial\", data = train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.7041  -0.4236  -0.2719  -0.1690   2.8375  \n",
       "\n",
       "Coefficients:\n",
       "                    Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)       -4.2411574  1.2938852  -3.278  0.00105 ** \n",
       "male               0.3869904  0.4379613   0.884  0.37690    \n",
       "race               0.8867192  0.3950660   2.244  0.02480 *  \n",
       "age               -0.0001756  0.0160852  -0.011  0.99129    \n",
       "state2             0.4433007  0.4816619   0.920  0.35739    \n",
       "state3             0.8349797  0.5562704   1.501  0.13335    \n",
       "state4            -3.3967878  0.6115860  -5.554 2.79e-08 ***\n",
       "time.served       -0.1238867  0.1204230  -1.029  0.30359    \n",
       "max.sentence       0.0802954  0.0553747   1.450  0.14705    \n",
       "multiple.offenses  1.6119919  0.3853050   4.184 2.87e-05 ***\n",
       "crime2             0.6837143  0.5003550   1.366  0.17180    \n",
       "crime3            -0.2781054  0.4328356  -0.643  0.52054    \n",
       "crime4            -0.0117627  0.5713035  -0.021  0.98357    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 340.04  on 472  degrees of freedom\n",
       "Residual deviance: 251.48  on 460  degrees of freedom\n",
       "AIC: 277.48\n",
       "\n",
       "Number of Fisher Scoring iterations: 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solution:\n",
    "\n",
    "mod = glm(violator~., data=train, family=\"binomial\")\n",
    "\n",
    "summary(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4.2 - Building a Logistic Regression Model\n",
    "\n",
    "What can we say based on the coefficient of the multiple.offenses variable?\n",
    "\n",
    "The following two properties might be useful to you when answering this question:\n",
    "\n",
    "1) If we have a coefficient c for a variable, then that means the log odds (or Logit) are increased by c for a unit increase in the variable.\n",
    "\n",
    "2) If we have a coefficient c for a variable, then that means the odds are multiplied by e^c for a unit increase in the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution: \n",
    " For parolees A and B who are identical other than A having committed multiple offenses, the predicted log odds of A is 1.61 more than the predicted log odds of B. Then we have:\n",
    "\n",
    "ln(odds of A) = ln(odds of B) + 1.61\n",
    "\n",
    "exp(ln(odds of A)) = exp(ln(odds of B) + 1.61)\n",
    "\n",
    "exp(ln(odds of A)) = exp(ln(odds of B)) * exp(1.61)\n",
    "\n",
    "odds of A = exp(1.61) * odds of B\n",
    "\n",
    "odds of A= 5.01 * odds of B\n",
    "\n",
    "In the second step we raised e to the power of both sides. In the third step we used the exponentiation rule that e^(a+b) = e^a * e^b. In the fourth step we used the rule that e^(ln(x)) = x. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4.3 - Building a Logistic Regression Model\n",
    "\n",
    "Consider a parolee who is male, of white race, aged 50 years at prison release, from the state of Maryland, served 3 months, had a maximum sentence of 12 months, did not commit multiple offenses, and committed a larceny. Answer the following questions based on the model's predictions for this individual. (HINT: You should use the coefficients of your model, the Logistic Response Function, and the Odds equation to solve this problem.)\n",
    "\n",
    "According to the model, what are the odds this individual is a violator?\n",
    "unanswered\n",
    "\n",
    "According to the model, what is the probability this individual is a violator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "From the logistic regression equation, we have log(odds) = -4.2411574 + 0.3869904*male + 0.8867192*race - 0.0001756*age + 0.4433007*state2 + 0.8349797*state3 - 3.3967878*state4 - 0.1238867*time.served + 0.0802954*max.sentence + 1.6119919*multiple.offenses + 0.6837143*crime2 - 0.2781054*crime3 - 0.0117627*crime4. This parolee has male=1, race=1, age=50, state2=0, state3=0, state4=0, time.served=3, max.sentence=12, multiple.offenses=0, crime2=1, crime3=0, crime4=0. We conclude that log(odds) = -1.700629.\n",
    "\n",
    "Therefore, the odds ratio is exp(-1.700629) = 0.183, and the predicted probability of violation is 1/(1+exp(1.700629)) = 0.154.\n",
    "\n",
    "See calculation below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "-1.7006288"
      ],
      "text/latex": [
       "-1.7006288"
      ],
      "text/markdown": [
       "-1.7006288"
      ],
      "text/plain": [
       "[1] -1.700629"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.182568652247076"
      ],
      "text/latex": [
       "0.182568652247076"
      ],
      "text/markdown": [
       "0.182568652247076"
      ],
      "text/plain": [
       "[1] 0.1825687"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plugging in values as stated above\n",
    "-4.2411574 + 0.3869904*1 + 0.8867192*1 - 0.0001756*50 + 0.4433007*0 + 0.8349797*0 - 3.3967878*0 -0.1238867*3 + 0.0802954*12 + 1.6119919*0 + 0.6837143*1 - 0.2781054*0 - 0.0117627*0\n",
    "\n",
    "# Therefore, odds ratio is .183 as represented by calculation below:\n",
    "exp(-1.700629)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on calculation above, the predicted probability of violation is calculated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.154383131922333"
      ],
      "text/latex": [
       "0.154383131922333"
      ],
      "text/markdown": [
       "0.154383131922333"
      ],
      "text/plain": [
       "[1] 0.1543831"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating probability of violation\n",
    "1/(1+exp(1.700629))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This individual is estimated to have a 15.4 % probability of violating their parole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5.1 - Evaluating the Model on the Testing Set\n",
    "\n",
    "Use the predict() function to obtain the model's predicted probabilities for parolees in the testing set, remembering to pass type=\"response\".\n",
    "\n",
    "What is the maximum predicted probability of a violation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n",
       "0.002334 0.023777 0.057905 0.146576 0.147452 0.907279 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = predict(mod, newdata=test, type=\"response\")\n",
    "summary(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum predicted probability of a violation is .907"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5.2 - Evaluating the Model on the Testing Set (answers inline)\n",
    "\n",
    "In the following questions, evaluate the model's predictions on the test set using a threshold of 0.5.\n",
    "\n",
    "What is the model's sensitivity?\n",
    "52.2%\n",
    "\n",
    "What is the model's specificity?\n",
    "93.3%\n",
    "\n",
    "What is the model's accuracy?\n",
    "88.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "      0   1\n",
       "  0 167  12\n",
       "  1  11  12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.886138613861386"
      ],
      "text/latex": [
       "0.886138613861386"
      ],
      "text/markdown": [
       "0.886138613861386"
      ],
      "text/plain": [
       "[1] 0.8861386"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.521739130434783"
      ],
      "text/latex": [
       "0.521739130434783"
      ],
      "text/markdown": [
       "0.521739130434783"
      ],
      "text/plain": [
       "[1] 0.5217391"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.932960893854749"
      ],
      "text/latex": [
       "0.932960893854749"
      ],
      "text/markdown": [
       "0.932960893854749"
      ],
      "text/plain": [
       "[1] 0.9329609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculations for above:\n",
    "\n",
    "# Obtain confusion matrix\n",
    "table(test$violator, as.numeric(predictions >= 0.5))\n",
    "\n",
    "# Accuracy of model (percentage we predicted correctly)\n",
    "(167+12)/202\n",
    "\n",
    "# Sensitivity (proportion of actual violators we got correct / true positives)\n",
    "12/(11+12)\n",
    "\n",
    "# Specificity (proportion of actual non-violators we got correct / true negatives)\n",
    "167/(167+12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5.3 - Evaluating the Model on the Testing Set\n",
    "\n",
    "What is the accuracy of a simple model that predicts that every parolee is a non-violator? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "179  23 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.886138613861386"
      ],
      "text/latex": [
       "0.886138613861386"
      ],
      "text/markdown": [
       "0.886138613861386"
      ],
      "text/plain": [
       "[1] 0.8861386"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solution:\n",
    "table(test$violator)\n",
    "179/(179+23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model predicting that every parolee is a non-violator would be accurate 88.6% of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5.4 - Evaluating the Model on the Testing Set\n",
    "\n",
    "Consider a parole board using the model to predict whether parolees will be violators or not. The job of a parole board is to make sure that a prisoner is ready to be released into free society, and therefore parole boards tend to be particularily concerned about releasing prisoners who will violate their parole. Which of the following most likely describes their preferences and best course of action?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "\n",
    "If the board used the model for parole decisions, a negative prediction would lead to a prisoner being granted parole, while a positive prediction would lead to a prisoner being denied parole. The parole board would experience more regret for releasing a prisoner who then violates parole (a negative prediction that is actually positive, or false negative) than it would experience for denying parole to a prisoner who would not have violated parole (a positive prediction that is actually negative, or false positive).\n",
    "\n",
    "Decreasing the cutoff leads to more positive predictions, which increases false positives and decreases false negatives. Meanwhile, increasing the cutoff leads to more negative predictions, which increases false negatives and decreases false positives. The parole board assigns high cost to false negatives, and therefore should decrease the cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5.5 - Evaluating the Model on the Testing Set\n",
    "\n",
    "Which of the following is the most accurate assessment of the value of the logistic regression model with a cutoff 0.5 to a parole board, based on the model's accuracy as compared to the simple baseline model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "\n",
    "The model at cutoff 0.5 has 12 false positives and 11 false negatives, while the baseline model has 0 false positives and 23 false negatives. Because a parole board is likely to assign more cost to a false negative, the model at cutoff 0.5 is likely of value to the board.\n",
    "\n",
    "From the previous question, the parole board would likely benefit from decreasing the logistic regression cutoffs, which decreases the false negative rate while increasing the false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 5.6 - Evaluating the Model on the Testing Set\n",
    "\n",
    "Using the ROCR package, what is the AUC value for the model? 0.8945834\n",
    "\n",
    "See calculation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.894583434539713"
      ],
      "text/latex": [
       "0.894583434539713"
      ],
      "text/markdown": [
       "0.894583434539713"
      ],
      "text/plain": [
       "[1] 0.8945834"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solution calculation:\n",
    "#install.packages('ROCR', repos='http://cran.us.r-project.org')\n",
    "library(ROCR)\n",
    "\n",
    "pred = prediction(predictions, test$violator)\n",
    "\n",
    "as.numeric(performance(pred, \"auc\")@y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5.7 - Evaluating the Model on the Testing Set\n",
    "\n",
    "Describe the meaning of AUC in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "\n",
    "The probability in the model can correctly differenciate between a randomly selected parole violator and a randomly selected parole non-violator.  In other words, the AUC deals with differentiating between a randomly selected positive and negative example. It is independent of the regression cutoff selected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 6.1 - Identifying Bias in Observational Data\n",
    "\n",
    "Our goal has been to predict the outcome of a parole decision, and we used a publicly available dataset of parole releases for predictions. In this final problem, we'll evaluate a potential source of bias associated with our analysis. It is always important to evaluate a dataset for possible sources of bias.\n",
    "\n",
    "The dataset contains all individuals released from parole in 2004, either due to completing their parole term or violating the terms of their parole. However, it does not contain parolees who neither violated their parole nor completed their term in 2004, causing non-violators to be underrepresented. This is called \"selection bias\" or \"selecting on the dependent variable,\" because only a subset of all relevant parolees were included in our analysis, based on our dependent variable in this analysis (parole violation). How could we improve our dataset to best address selection bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "We should use a dataset tracking a group of parolees from the start of their parole until either they violated parole or they completed their term.\n",
    "\n",
    "While expanding the dataset to include the missing parolees and labeling each as violator=0 would improve the representation of non-violators, it does not capture the true outcome, since the parolee might become a violator after 2004. Though labeling these new examples with violator=NA correctly identifies that we don't know their true outcome, we cannot train or test a prediction model with a missing dependent variable.\n",
    "\n",
    "As a result, a prospective dataset that tracks a cohort of parolees and observes the true outcome of each is more desirable. Unfortunately, such datasets are often more challenging to obtain (for instance, if a parolee had a 10-year term, it might require tracking that individual for 10 years before building the model). Such a prospective analysis would not be possible using the 2004 National Corrections Reporting Program dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
